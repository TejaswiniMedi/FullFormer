import os
import random
from glob import glob
import numpy as np
from collections import defaultdict
train_all = []
test_all = []
val_all = []
n_test = None
n_val = None
# parse all input files.
print('Finding raw files for preprocessing.')

# data_dir should be assigned with input data directory.


# path to load .obj files of the input data.

paths = glob(path)
print(len(paths))
paths = [os.path.dirname(p) for p in paths]
class_folders = None

# sort according to class folders (optional)
if class_folders is None:
    res = {'single_class': paths}
else:
    class_paths = glob( data_dir + class_folders)
    res = defaultdict(list)
    for path in paths:
        for class_path in class_paths:
            if path.startswith(class_path):
                res[class_path].append(path)
for class_path in res.keys():
    all_samples = res[class_path]
    print(all_samples)
    random.shuffle(all_samples)
    # Number of examples
    n_total = len(all_samples)
    if n_val is not None:
        n_val = n_val
    else:
        n_val = int(0.2* n_total)
    if n_test is not None:
        n_test = n_test
    else:
        n_test = int(0.1 * n_total)
    if n_total < n_val + n_test:
        print('Error: too few training samples.')
        exit()
    n_train = n_total - n_val - n_test
    print(n_train,n_val,n_test)
    assert(n_train >= 0)
    # Select elements
    train_all.extend( all_samples[:n_train])
    val_all.extend( all_samples[n_train:n_train+n_val])
    test_all.extend( all_samples[n_train+n_val:])
# save the split file which stores train-validation-test split information of given dataset
np.savez(data_dir + f'/../{"split"}.npz', train = train_all, test = test_all, val = val_all)
